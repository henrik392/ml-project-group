# Experiment 6: SAHI Tiled Inference
# Purpose: Test slicing-aided inference for small object detection

experiment_id: exp06_sahi
description: "SAHI tiled inference (accuracy vs speed tradeoff)"

# Model configuration (use trained baseline)
model: yolov11n
weights: runs/train/yolov11n_baseline_fold0/weights/best.pt  # From exp02

# Dataset
data: configs/dataset_fold_0.yaml
fold_id: 0

# Training parameters (inference only)
skip_training: true

# Inference configuration
inference:
  mode: sahi
  conf: 0.01  # Optimal from exp03 (F2=0.088)
  iou: 0.45

  # SAHI-specific settings
  sahi:
    slice_height: 640
    slice_width: 640
    overlap_height_ratio: 0.2
    overlap_width_ratio: 0.2
    postprocess_type: NMS  # or GREEDYNMM
    postprocess_match_metric: IOS  # or IOU
    postprocess_match_threshold: 0.5

# Tracking
tracking:
  enabled: false

# Evaluation
eval_video_id: video_0

# Notes
notes: |
  SAHI divides images into overlapping tiles for better small object detection.
  Expected: +50-100% recall on tiny objects.
  Trade-off: 2-6Ã— slower inference.
  Use frozen baseline weights from exp02.
  Compare accuracy gain vs. speed penalty.
